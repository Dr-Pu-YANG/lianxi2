{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import yfinance as yf\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True, theme='pearl')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  16 of 16 completed\n"
     ]
    }
   ],
   "source": [
    "# Commodity futures' short codes (tickers) and corresponding human-readable names (labels)\n",
    "tickers = ['CC=F', 'CL=F', 'CT=F',\n",
    "           'GC=F', 'HE=F', 'HG=F',\n",
    "           'KC=F', 'LBS=F', 'LE=F', \n",
    "           'NG=F', 'PA=F', 'PL=F', \n",
    "           'SB=F', 'SI=F', 'ZM=F',\n",
    "           '^GSPC']\n",
    "\n",
    "labels = ['Cocoa', 'Crude Oil WTI', 'Cotton', \n",
    "          'Gold', 'Lean Hogs', 'Copper', \n",
    "          'Coffee', 'Lumber', 'Live Cattle',\n",
    "          'Natural Gas', 'Palladium', 'Platinum', \n",
    "          'Sugar', 'Silver', 'Corn',\n",
    "          'S&P500']\n",
    "\n",
    "# Download data from Yahoo Finance\n",
    "df = yf.download([tick for tick in tickers], start=datetime.date(2004, 8, 1), end=datetime.date(2023, 7, 31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cocoa</th>\n",
       "      <th>Crude Oil WTI</th>\n",
       "      <th>Cotton</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Live Cattle</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Palladium</th>\n",
       "      <th>Platinum</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Corn</th>\n",
       "      <th>S&amp;P500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-02 00:00:00-04:00</th>\n",
       "      <td>1692.0</td>\n",
       "      <td>43.820000</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>391.700012</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>1.3080</td>\n",
       "      <td>66.449997</td>\n",
       "      <td>412.299988</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>5.813</td>\n",
       "      <td>218.899994</td>\n",
       "      <td>826.299988</td>\n",
       "      <td>8.390000</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>192.800003</td>\n",
       "      <td>1106.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-03 00:00:00-04:00</th>\n",
       "      <td>1723.0</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>45.459999</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>1.3060</td>\n",
       "      <td>66.800003</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>83.074997</td>\n",
       "      <td>5.816</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>829.099976</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>1099.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-04 00:00:00-04:00</th>\n",
       "      <td>1727.0</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>44.950001</td>\n",
       "      <td>392.200012</td>\n",
       "      <td>78.550003</td>\n",
       "      <td>1.2980</td>\n",
       "      <td>66.300003</td>\n",
       "      <td>428.500000</td>\n",
       "      <td>84.824997</td>\n",
       "      <td>5.661</td>\n",
       "      <td>218.449997</td>\n",
       "      <td>831.200012</td>\n",
       "      <td>8.150000</td>\n",
       "      <td>6.727000</td>\n",
       "      <td>183.800003</td>\n",
       "      <td>1098.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-05 00:00:00-04:00</th>\n",
       "      <td>1703.0</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>392.299988</td>\n",
       "      <td>78.625000</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>431.299988</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.712</td>\n",
       "      <td>213.399994</td>\n",
       "      <td>827.299988</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>186.800003</td>\n",
       "      <td>1080.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-06 00:00:00-04:00</th>\n",
       "      <td>1610.0</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>399.799988</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>1.2820</td>\n",
       "      <td>67.050003</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.588</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>6.767000</td>\n",
       "      <td>188.699997</td>\n",
       "      <td>1063.969971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-09 00:00:00-04:00</th>\n",
       "      <td>3229.0</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>80.989998</td>\n",
       "      <td>2036.199951</td>\n",
       "      <td>76.275002</td>\n",
       "      <td>3.8890</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>163.925003</td>\n",
       "      <td>2.267</td>\n",
       "      <td>1587.699951</td>\n",
       "      <td>1117.099976</td>\n",
       "      <td>26.190001</td>\n",
       "      <td>25.698000</td>\n",
       "      <td>416.399994</td>\n",
       "      <td>4119.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10 00:00:00-04:00</th>\n",
       "      <td>3260.0</td>\n",
       "      <td>72.559998</td>\n",
       "      <td>80.760002</td>\n",
       "      <td>2030.500000</td>\n",
       "      <td>76.574997</td>\n",
       "      <td>3.8280</td>\n",
       "      <td>187.449997</td>\n",
       "      <td>348.899994</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>2.191</td>\n",
       "      <td>1613.099976</td>\n",
       "      <td>1122.199951</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>25.461000</td>\n",
       "      <td>417.899994</td>\n",
       "      <td>4137.640137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 00:00:00-04:00</th>\n",
       "      <td>3242.0</td>\n",
       "      <td>70.870003</td>\n",
       "      <td>79.620003</td>\n",
       "      <td>2014.699951</td>\n",
       "      <td>76.599998</td>\n",
       "      <td>3.6975</td>\n",
       "      <td>185.800003</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>162.949997</td>\n",
       "      <td>2.190</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1108.099976</td>\n",
       "      <td>26.020000</td>\n",
       "      <td>24.254999</td>\n",
       "      <td>426.600006</td>\n",
       "      <td>4130.620117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12 00:00:00-04:00</th>\n",
       "      <td>3226.0</td>\n",
       "      <td>70.040001</td>\n",
       "      <td>80.529999</td>\n",
       "      <td>2014.500000</td>\n",
       "      <td>76.625000</td>\n",
       "      <td>3.7165</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>2.266</td>\n",
       "      <td>1521.800049</td>\n",
       "      <td>1070.099976</td>\n",
       "      <td>26.219999</td>\n",
       "      <td>23.992001</td>\n",
       "      <td>428.100006</td>\n",
       "      <td>4124.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-15 00:00:00-04:00</th>\n",
       "      <td>3160.0</td>\n",
       "      <td>71.110001</td>\n",
       "      <td>82.370003</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>3.7375</td>\n",
       "      <td>193.050003</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>164.324997</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1538.300049</td>\n",
       "      <td>1077.800049</td>\n",
       "      <td>26.290001</td>\n",
       "      <td>24.127001</td>\n",
       "      <td>430.899994</td>\n",
       "      <td>4136.279785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3858 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Cocoa  Crude Oil WTI     Cotton         Gold  \\\n",
       "Date                                                                       \n",
       "2004-08-02 00:00:00-04:00  1692.0      43.820000  44.299999   391.700012   \n",
       "2004-08-03 00:00:00-04:00  1723.0      44.150002  45.459999   394.000000   \n",
       "2004-08-04 00:00:00-04:00  1727.0      42.830002  44.950001   392.200012   \n",
       "2004-08-05 00:00:00-04:00  1703.0      44.410000  45.730000   392.299988   \n",
       "2004-08-06 00:00:00-04:00  1610.0      43.950001  44.900002   399.799988   \n",
       "...                           ...            ...        ...          ...   \n",
       "2023-05-09 00:00:00-04:00  3229.0      73.709999  80.989998  2036.199951   \n",
       "2023-05-10 00:00:00-04:00  3260.0      72.559998  80.760002  2030.500000   \n",
       "2023-05-11 00:00:00-04:00  3242.0      70.870003  79.620003  2014.699951   \n",
       "2023-05-12 00:00:00-04:00  3226.0      70.040001  80.529999  2014.500000   \n",
       "2023-05-15 00:00:00-04:00  3160.0      71.110001  82.370003  2018.000000   \n",
       "\n",
       "                           Lean Hogs  Copper      Coffee      Lumber  \\\n",
       "Date                                                                   \n",
       "2004-08-02 00:00:00-04:00  78.500000  1.3080   66.449997  412.299988   \n",
       "2004-08-03 00:00:00-04:00  77.375000  1.3060   66.800003  418.500000   \n",
       "2004-08-04 00:00:00-04:00  78.550003  1.2980   66.300003  428.500000   \n",
       "2004-08-05 00:00:00-04:00  78.625000  1.2840   65.900002  431.299988   \n",
       "2004-08-06 00:00:00-04:00  79.250000  1.2820   67.050003  428.000000   \n",
       "...                              ...     ...         ...         ...   \n",
       "2023-05-09 00:00:00-04:00  76.275002  3.8890  188.000000  344.000000   \n",
       "2023-05-10 00:00:00-04:00  76.574997  3.8280  187.449997  348.899994   \n",
       "2023-05-11 00:00:00-04:00  76.599998  3.6975  185.800003  345.000000   \n",
       "2023-05-12 00:00:00-04:00  76.625000  3.7165  186.000000  339.000000   \n",
       "2023-05-15 00:00:00-04:00  86.150002  3.7375  193.050003  344.000000   \n",
       "\n",
       "                           Live Cattle  Natural Gas    Palladium     Platinum  \\\n",
       "Date                                                                            \n",
       "2004-08-02 00:00:00-04:00    85.250000        5.813   218.899994   826.299988   \n",
       "2004-08-03 00:00:00-04:00    83.074997        5.816   217.500000   829.099976   \n",
       "2004-08-04 00:00:00-04:00    84.824997        5.661   218.449997   831.200012   \n",
       "2004-08-05 00:00:00-04:00    84.550003        5.712   213.399994   827.299988   \n",
       "2004-08-06 00:00:00-04:00    84.550003        5.588   214.000000   832.000000   \n",
       "...                                ...          ...          ...          ...   \n",
       "2023-05-09 00:00:00-04:00   163.925003        2.267  1587.699951  1117.099976   \n",
       "2023-05-10 00:00:00-04:00   163.000000        2.191  1613.099976  1122.199951   \n",
       "2023-05-11 00:00:00-04:00   162.949997        2.190  1562.000000  1108.099976   \n",
       "2023-05-12 00:00:00-04:00   164.399994        2.266  1521.800049  1070.099976   \n",
       "2023-05-15 00:00:00-04:00   164.324997        2.375  1538.300049  1077.800049   \n",
       "\n",
       "                               Sugar     Silver        Corn       S&P500  \n",
       "Date                                                                      \n",
       "2004-08-02 00:00:00-04:00   8.390000   6.610000  192.800003  1106.619995  \n",
       "2004-08-03 00:00:00-04:00   8.380000   6.675000  188.000000  1099.689941  \n",
       "2004-08-04 00:00:00-04:00   8.150000   6.727000  183.800003  1098.630005  \n",
       "2004-08-05 00:00:00-04:00   8.130000   6.740000  186.800003  1080.699951  \n",
       "2004-08-06 00:00:00-04:00   8.170000   6.767000  188.699997  1063.969971  \n",
       "...                              ...        ...         ...          ...  \n",
       "2023-05-09 00:00:00-04:00  26.190001  25.698000  416.399994  4119.169922  \n",
       "2023-05-10 00:00:00-04:00  26.660000  25.461000  417.899994  4137.640137  \n",
       "2023-05-11 00:00:00-04:00  26.020000  24.254999  426.600006  4130.620117  \n",
       "2023-05-12 00:00:00-04:00  26.219999  23.992001  428.100006  4124.080078  \n",
       "2023-05-15 00:00:00-04:00  26.290001  24.127001  430.899994  4136.279785  \n",
       "\n",
       "[3858 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null values\n",
    "price = df['Adj Close'].dropna()\n",
    "\n",
    "# Change the table headers from tickers to labels for better understanding\n",
    "price.columns = [labels[tickers.index(tick)] for tick in list(price.columns)]\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cocoa</th>\n",
       "      <th>Crude Oil WTI</th>\n",
       "      <th>Cotton</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Live Cattle</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Palladium</th>\n",
       "      <th>Platinum</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Corn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-02 00:00:00-04:00</th>\n",
       "      <td>1692.0</td>\n",
       "      <td>43.820000</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>391.700012</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>1.3080</td>\n",
       "      <td>66.449997</td>\n",
       "      <td>412.299988</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>5.813</td>\n",
       "      <td>218.899994</td>\n",
       "      <td>826.299988</td>\n",
       "      <td>8.390000</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>192.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-03 00:00:00-04:00</th>\n",
       "      <td>1723.0</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>45.459999</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>1.3060</td>\n",
       "      <td>66.800003</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>83.074997</td>\n",
       "      <td>5.816</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>829.099976</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-04 00:00:00-04:00</th>\n",
       "      <td>1727.0</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>44.950001</td>\n",
       "      <td>392.200012</td>\n",
       "      <td>78.550003</td>\n",
       "      <td>1.2980</td>\n",
       "      <td>66.300003</td>\n",
       "      <td>428.500000</td>\n",
       "      <td>84.824997</td>\n",
       "      <td>5.661</td>\n",
       "      <td>218.449997</td>\n",
       "      <td>831.200012</td>\n",
       "      <td>8.150000</td>\n",
       "      <td>6.727000</td>\n",
       "      <td>183.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-05 00:00:00-04:00</th>\n",
       "      <td>1703.0</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>392.299988</td>\n",
       "      <td>78.625000</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>431.299988</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.712</td>\n",
       "      <td>213.399994</td>\n",
       "      <td>827.299988</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>186.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-06 00:00:00-04:00</th>\n",
       "      <td>1610.0</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>399.799988</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>1.2820</td>\n",
       "      <td>67.050003</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.588</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>6.767000</td>\n",
       "      <td>188.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-09 00:00:00-04:00</th>\n",
       "      <td>3229.0</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>80.989998</td>\n",
       "      <td>2036.199951</td>\n",
       "      <td>76.275002</td>\n",
       "      <td>3.8890</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>163.925003</td>\n",
       "      <td>2.267</td>\n",
       "      <td>1587.699951</td>\n",
       "      <td>1117.099976</td>\n",
       "      <td>26.190001</td>\n",
       "      <td>25.698000</td>\n",
       "      <td>416.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10 00:00:00-04:00</th>\n",
       "      <td>3260.0</td>\n",
       "      <td>72.559998</td>\n",
       "      <td>80.760002</td>\n",
       "      <td>2030.500000</td>\n",
       "      <td>76.574997</td>\n",
       "      <td>3.8280</td>\n",
       "      <td>187.449997</td>\n",
       "      <td>348.899994</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>2.191</td>\n",
       "      <td>1613.099976</td>\n",
       "      <td>1122.199951</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>25.461000</td>\n",
       "      <td>417.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 00:00:00-04:00</th>\n",
       "      <td>3242.0</td>\n",
       "      <td>70.870003</td>\n",
       "      <td>79.620003</td>\n",
       "      <td>2014.699951</td>\n",
       "      <td>76.599998</td>\n",
       "      <td>3.6975</td>\n",
       "      <td>185.800003</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>162.949997</td>\n",
       "      <td>2.190</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>1108.099976</td>\n",
       "      <td>26.020000</td>\n",
       "      <td>24.254999</td>\n",
       "      <td>426.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12 00:00:00-04:00</th>\n",
       "      <td>3226.0</td>\n",
       "      <td>70.040001</td>\n",
       "      <td>80.529999</td>\n",
       "      <td>2014.500000</td>\n",
       "      <td>76.625000</td>\n",
       "      <td>3.7165</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>2.266</td>\n",
       "      <td>1521.800049</td>\n",
       "      <td>1070.099976</td>\n",
       "      <td>26.219999</td>\n",
       "      <td>23.992001</td>\n",
       "      <td>428.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-15 00:00:00-04:00</th>\n",
       "      <td>3160.0</td>\n",
       "      <td>71.110001</td>\n",
       "      <td>82.370003</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>3.7375</td>\n",
       "      <td>193.050003</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>164.324997</td>\n",
       "      <td>2.375</td>\n",
       "      <td>1538.300049</td>\n",
       "      <td>1077.800049</td>\n",
       "      <td>26.290001</td>\n",
       "      <td>24.127001</td>\n",
       "      <td>430.899994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3858 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Cocoa  Crude Oil WTI     Cotton         Gold  \\\n",
       "Date                                                                       \n",
       "2004-08-02 00:00:00-04:00  1692.0      43.820000  44.299999   391.700012   \n",
       "2004-08-03 00:00:00-04:00  1723.0      44.150002  45.459999   394.000000   \n",
       "2004-08-04 00:00:00-04:00  1727.0      42.830002  44.950001   392.200012   \n",
       "2004-08-05 00:00:00-04:00  1703.0      44.410000  45.730000   392.299988   \n",
       "2004-08-06 00:00:00-04:00  1610.0      43.950001  44.900002   399.799988   \n",
       "...                           ...            ...        ...          ...   \n",
       "2023-05-09 00:00:00-04:00  3229.0      73.709999  80.989998  2036.199951   \n",
       "2023-05-10 00:00:00-04:00  3260.0      72.559998  80.760002  2030.500000   \n",
       "2023-05-11 00:00:00-04:00  3242.0      70.870003  79.620003  2014.699951   \n",
       "2023-05-12 00:00:00-04:00  3226.0      70.040001  80.529999  2014.500000   \n",
       "2023-05-15 00:00:00-04:00  3160.0      71.110001  82.370003  2018.000000   \n",
       "\n",
       "                           Lean Hogs  Copper      Coffee      Lumber  \\\n",
       "Date                                                                   \n",
       "2004-08-02 00:00:00-04:00  78.500000  1.3080   66.449997  412.299988   \n",
       "2004-08-03 00:00:00-04:00  77.375000  1.3060   66.800003  418.500000   \n",
       "2004-08-04 00:00:00-04:00  78.550003  1.2980   66.300003  428.500000   \n",
       "2004-08-05 00:00:00-04:00  78.625000  1.2840   65.900002  431.299988   \n",
       "2004-08-06 00:00:00-04:00  79.250000  1.2820   67.050003  428.000000   \n",
       "...                              ...     ...         ...         ...   \n",
       "2023-05-09 00:00:00-04:00  76.275002  3.8890  188.000000  344.000000   \n",
       "2023-05-10 00:00:00-04:00  76.574997  3.8280  187.449997  348.899994   \n",
       "2023-05-11 00:00:00-04:00  76.599998  3.6975  185.800003  345.000000   \n",
       "2023-05-12 00:00:00-04:00  76.625000  3.7165  186.000000  339.000000   \n",
       "2023-05-15 00:00:00-04:00  86.150002  3.7375  193.050003  344.000000   \n",
       "\n",
       "                           Live Cattle  Natural Gas    Palladium     Platinum  \\\n",
       "Date                                                                            \n",
       "2004-08-02 00:00:00-04:00    85.250000        5.813   218.899994   826.299988   \n",
       "2004-08-03 00:00:00-04:00    83.074997        5.816   217.500000   829.099976   \n",
       "2004-08-04 00:00:00-04:00    84.824997        5.661   218.449997   831.200012   \n",
       "2004-08-05 00:00:00-04:00    84.550003        5.712   213.399994   827.299988   \n",
       "2004-08-06 00:00:00-04:00    84.550003        5.588   214.000000   832.000000   \n",
       "...                                ...          ...          ...          ...   \n",
       "2023-05-09 00:00:00-04:00   163.925003        2.267  1587.699951  1117.099976   \n",
       "2023-05-10 00:00:00-04:00   163.000000        2.191  1613.099976  1122.199951   \n",
       "2023-05-11 00:00:00-04:00   162.949997        2.190  1562.000000  1108.099976   \n",
       "2023-05-12 00:00:00-04:00   164.399994        2.266  1521.800049  1070.099976   \n",
       "2023-05-15 00:00:00-04:00   164.324997        2.375  1538.300049  1077.800049   \n",
       "\n",
       "                               Sugar     Silver        Corn  \n",
       "Date                                                         \n",
       "2004-08-02 00:00:00-04:00   8.390000   6.610000  192.800003  \n",
       "2004-08-03 00:00:00-04:00   8.380000   6.675000  188.000000  \n",
       "2004-08-04 00:00:00-04:00   8.150000   6.727000  183.800003  \n",
       "2004-08-05 00:00:00-04:00   8.130000   6.740000  186.800003  \n",
       "2004-08-06 00:00:00-04:00   8.170000   6.767000  188.699997  \n",
       "...                              ...        ...         ...  \n",
       "2023-05-09 00:00:00-04:00  26.190001  25.698000  416.399994  \n",
       "2023-05-10 00:00:00-04:00  26.660000  25.461000  417.899994  \n",
       "2023-05-11 00:00:00-04:00  26.020000  24.254999  426.600006  \n",
       "2023-05-12 00:00:00-04:00  26.219999  23.992001  428.100006  \n",
       "2023-05-15 00:00:00-04:00  26.290001  24.127001  430.899994  \n",
       "\n",
       "[3858 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the SP500 price\n",
    "commodity = price.drop(columns=['S&P500'])\n",
    "commodity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cocoa</th>\n",
       "      <th>Crude Oil WTI</th>\n",
       "      <th>Cotton</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Lean Hogs</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Coffee</th>\n",
       "      <th>Lumber</th>\n",
       "      <th>Live Cattle</th>\n",
       "      <th>Natural Gas</th>\n",
       "      <th>Palladium</th>\n",
       "      <th>Platinum</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Corn</th>\n",
       "      <th>S&amp;P500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-02 00:00:00-04:00</th>\n",
       "      <td>1692.0</td>\n",
       "      <td>43.820000</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>391.700012</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>1.3080</td>\n",
       "      <td>66.449997</td>\n",
       "      <td>412.299988</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>5.813</td>\n",
       "      <td>218.899994</td>\n",
       "      <td>826.299988</td>\n",
       "      <td>8.39</td>\n",
       "      <td>6.610</td>\n",
       "      <td>192.800003</td>\n",
       "      <td>1106.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-03 00:00:00-04:00</th>\n",
       "      <td>1723.0</td>\n",
       "      <td>44.150002</td>\n",
       "      <td>45.459999</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>77.375000</td>\n",
       "      <td>1.3060</td>\n",
       "      <td>66.800003</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>83.074997</td>\n",
       "      <td>5.816</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>829.099976</td>\n",
       "      <td>8.38</td>\n",
       "      <td>6.675</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>1099.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-04 00:00:00-04:00</th>\n",
       "      <td>1727.0</td>\n",
       "      <td>42.830002</td>\n",
       "      <td>44.950001</td>\n",
       "      <td>392.200012</td>\n",
       "      <td>78.550003</td>\n",
       "      <td>1.2980</td>\n",
       "      <td>66.300003</td>\n",
       "      <td>428.500000</td>\n",
       "      <td>84.824997</td>\n",
       "      <td>5.661</td>\n",
       "      <td>218.449997</td>\n",
       "      <td>831.200012</td>\n",
       "      <td>8.15</td>\n",
       "      <td>6.727</td>\n",
       "      <td>183.800003</td>\n",
       "      <td>1098.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-05 00:00:00-04:00</th>\n",
       "      <td>1703.0</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>392.299988</td>\n",
       "      <td>78.625000</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>431.299988</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.712</td>\n",
       "      <td>213.399994</td>\n",
       "      <td>827.299988</td>\n",
       "      <td>8.13</td>\n",
       "      <td>6.740</td>\n",
       "      <td>186.800003</td>\n",
       "      <td>1080.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-06 00:00:00-04:00</th>\n",
       "      <td>1610.0</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>399.799988</td>\n",
       "      <td>79.250000</td>\n",
       "      <td>1.2820</td>\n",
       "      <td>67.050003</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>84.550003</td>\n",
       "      <td>5.588</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>8.17</td>\n",
       "      <td>6.767</td>\n",
       "      <td>188.699997</td>\n",
       "      <td>1063.969971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-10 00:00:00-04:00</th>\n",
       "      <td>2329.0</td>\n",
       "      <td>67.540001</td>\n",
       "      <td>83.930000</td>\n",
       "      <td>1193.000000</td>\n",
       "      <td>55.950001</td>\n",
       "      <td>2.6105</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>110.150002</td>\n",
       "      <td>2.804</td>\n",
       "      <td>983.599976</td>\n",
       "      <td>788.799988</td>\n",
       "      <td>11.20</td>\n",
       "      <td>14.079</td>\n",
       "      <td>315.899994</td>\n",
       "      <td>2877.129883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 00:00:00-04:00</th>\n",
       "      <td>2283.0</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>83.029999</td>\n",
       "      <td>1195.400024</td>\n",
       "      <td>54.474998</td>\n",
       "      <td>2.6040</td>\n",
       "      <td>96.199997</td>\n",
       "      <td>443.100006</td>\n",
       "      <td>109.300003</td>\n",
       "      <td>2.828</td>\n",
       "      <td>980.900024</td>\n",
       "      <td>788.099976</td>\n",
       "      <td>11.18</td>\n",
       "      <td>14.052</td>\n",
       "      <td>314.200012</td>\n",
       "      <td>2887.889893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-12 00:00:00-04:00</th>\n",
       "      <td>2355.0</td>\n",
       "      <td>70.370003</td>\n",
       "      <td>82.760002</td>\n",
       "      <td>1204.699951</td>\n",
       "      <td>55.799999</td>\n",
       "      <td>2.6585</td>\n",
       "      <td>97.849998</td>\n",
       "      <td>433.299988</td>\n",
       "      <td>111.474998</td>\n",
       "      <td>2.829</td>\n",
       "      <td>993.299988</td>\n",
       "      <td>798.700012</td>\n",
       "      <td>11.67</td>\n",
       "      <td>14.192</td>\n",
       "      <td>315.700012</td>\n",
       "      <td>2888.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-13 00:00:00-04:00</th>\n",
       "      <td>2314.0</td>\n",
       "      <td>68.589996</td>\n",
       "      <td>81.620003</td>\n",
       "      <td>1202.000000</td>\n",
       "      <td>55.674999</td>\n",
       "      <td>2.6645</td>\n",
       "      <td>96.400002</td>\n",
       "      <td>434.700012</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>2.817</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>802.099976</td>\n",
       "      <td>11.68</td>\n",
       "      <td>14.143</td>\n",
       "      <td>311.299988</td>\n",
       "      <td>2904.179932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14 00:00:00-04:00</th>\n",
       "      <td>2219.0</td>\n",
       "      <td>68.989998</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>1195.000000</td>\n",
       "      <td>56.224998</td>\n",
       "      <td>2.6275</td>\n",
       "      <td>95.449997</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>113.800003</td>\n",
       "      <td>2.767</td>\n",
       "      <td>998.799988</td>\n",
       "      <td>797.400024</td>\n",
       "      <td>11.16</td>\n",
       "      <td>14.042</td>\n",
       "      <td>307.299988</td>\n",
       "      <td>2904.979980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Cocoa  Crude Oil WTI     Cotton         Gold  \\\n",
       "Date                                                                       \n",
       "2004-08-02 00:00:00-04:00  1692.0      43.820000  44.299999   391.700012   \n",
       "2004-08-03 00:00:00-04:00  1723.0      44.150002  45.459999   394.000000   \n",
       "2004-08-04 00:00:00-04:00  1727.0      42.830002  44.950001   392.200012   \n",
       "2004-08-05 00:00:00-04:00  1703.0      44.410000  45.730000   392.299988   \n",
       "2004-08-06 00:00:00-04:00  1610.0      43.950001  44.900002   399.799988   \n",
       "...                           ...            ...        ...          ...   \n",
       "2018-09-10 00:00:00-04:00  2329.0      67.540001  83.930000  1193.000000   \n",
       "2018-09-11 00:00:00-04:00  2283.0      69.250000  83.029999  1195.400024   \n",
       "2018-09-12 00:00:00-04:00  2355.0      70.370003  82.760002  1204.699951   \n",
       "2018-09-13 00:00:00-04:00  2314.0      68.589996  81.620003  1202.000000   \n",
       "2018-09-14 00:00:00-04:00  2219.0      68.989998  81.900002  1195.000000   \n",
       "\n",
       "                           Lean Hogs  Copper     Coffee      Lumber  \\\n",
       "Date                                                                  \n",
       "2004-08-02 00:00:00-04:00  78.500000  1.3080  66.449997  412.299988   \n",
       "2004-08-03 00:00:00-04:00  77.375000  1.3060  66.800003  418.500000   \n",
       "2004-08-04 00:00:00-04:00  78.550003  1.2980  66.300003  428.500000   \n",
       "2004-08-05 00:00:00-04:00  78.625000  1.2840  65.900002  431.299988   \n",
       "2004-08-06 00:00:00-04:00  79.250000  1.2820  67.050003  428.000000   \n",
       "...                              ...     ...        ...         ...   \n",
       "2018-09-10 00:00:00-04:00  55.950001  2.6105  97.500000  445.000000   \n",
       "2018-09-11 00:00:00-04:00  54.474998  2.6040  96.199997  443.100006   \n",
       "2018-09-12 00:00:00-04:00  55.799999  2.6585  97.849998  433.299988   \n",
       "2018-09-13 00:00:00-04:00  55.674999  2.6645  96.400002  434.700012   \n",
       "2018-09-14 00:00:00-04:00  56.224998  2.6275  95.449997  420.000000   \n",
       "\n",
       "                           Live Cattle  Natural Gas   Palladium    Platinum  \\\n",
       "Date                                                                          \n",
       "2004-08-02 00:00:00-04:00    85.250000        5.813  218.899994  826.299988   \n",
       "2004-08-03 00:00:00-04:00    83.074997        5.816  217.500000  829.099976   \n",
       "2004-08-04 00:00:00-04:00    84.824997        5.661  218.449997  831.200012   \n",
       "2004-08-05 00:00:00-04:00    84.550003        5.712  213.399994  827.299988   \n",
       "2004-08-06 00:00:00-04:00    84.550003        5.588  214.000000  832.000000   \n",
       "...                                ...          ...         ...         ...   \n",
       "2018-09-10 00:00:00-04:00   110.150002        2.804  983.599976  788.799988   \n",
       "2018-09-11 00:00:00-04:00   109.300003        2.828  980.900024  788.099976   \n",
       "2018-09-12 00:00:00-04:00   111.474998        2.829  993.299988  798.700012   \n",
       "2018-09-13 00:00:00-04:00   110.800003        2.817  997.000000  802.099976   \n",
       "2018-09-14 00:00:00-04:00   113.800003        2.767  998.799988  797.400024   \n",
       "\n",
       "                           Sugar  Silver        Corn       S&P500  \n",
       "Date                                                               \n",
       "2004-08-02 00:00:00-04:00   8.39   6.610  192.800003  1106.619995  \n",
       "2004-08-03 00:00:00-04:00   8.38   6.675  188.000000  1099.689941  \n",
       "2004-08-04 00:00:00-04:00   8.15   6.727  183.800003  1098.630005  \n",
       "2004-08-05 00:00:00-04:00   8.13   6.740  186.800003  1080.699951  \n",
       "2004-08-06 00:00:00-04:00   8.17   6.767  188.699997  1063.969971  \n",
       "...                          ...     ...         ...          ...  \n",
       "2018-09-10 00:00:00-04:00  11.20  14.079  315.899994  2877.129883  \n",
       "2018-09-11 00:00:00-04:00  11.18  14.052  314.200012  2887.889893  \n",
       "2018-09-12 00:00:00-04:00  11.67  14.192  315.700012  2888.919922  \n",
       "2018-09-13 00:00:00-04:00  11.68  14.143  311.299988  2904.179932  \n",
       "2018-09-14 00:00:00-04:00  11.16  14.042  307.299988  2904.979980  \n",
       "\n",
       "[2700 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "price_train = price[:int(len(price)*0.7)]\n",
    "price_test = price[int(len(price)*0.7):]\n",
    "price_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the SP500 price\n",
    "commodity_train = price_train.drop(columns=['S&P500'])\n",
    "commodity_test = price_test.drop(columns=['S&P500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory Data Matrix\n",
    "def Explanatory(X, p):\n",
    "    \"\"\"\n",
    "    This function forms an explanatory matrix with lag p for the computation of OLS().\n",
    "    \n",
    "    Input:\n",
    "    X: explanatory variables (each column is a time series variable)\n",
    "    p: number of lags which specifies how many lagged values of the explanatory variable will be included\n",
    "    \n",
    "    Output: \n",
    "    Z: an explanatory data matrix with ones in the first row\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of observations\n",
    "    T = len(X)\n",
    "\n",
    "    # Explanatory matrix  \n",
    "    if isinstance(X, pd.Series): # whether X includes only one variable\n",
    "        Z = np.array(np.ones(T-p)) # initialize the matrix with a row of ones used for the constant term in the regression (intercept)\n",
    "        Z = np.vstack((Z, X[p:].T)) # stack the lagged values from the second row\n",
    "        return Z\n",
    "    else:\n",
    "        Z = np.array(np.ones(T-p))\n",
    "        if p==0:\n",
    "            Z = np.vstack((Z, X.values.T)) \n",
    "        else:\n",
    "            for i in range(1, p+1):\n",
    "                Z = np.vstack((Z, X[p-i:T-i].values.T))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression\n",
    "def OLS(Z, Y):\n",
    "    \"\"\"\n",
    "    This function is used to calculate the OLS regression.\n",
    "\n",
    "    Input:\n",
    "        Z: explanatory data matrix with ones in the top row\n",
    "        Y: dependent matrix\n",
    "    \n",
    "    Output: \n",
    "        Estimates: beta coefficient\n",
    "        Std. Err: standard error \n",
    "        t-Statistic: test statistic\n",
    "        Pr(>|t|): p value\n",
    "        AIC: Akaike information criterion (only for VAR model)\n",
    "        SC: Schwarz criterion (only for VAR model)\n",
    "        Residuals: Disturbance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of assets in Z and Y\n",
    "    N_z = Z.shape[0]\n",
    "    if Y.ndim == 1:\n",
    "        N_y = Y.ndim\n",
    "    else:\n",
    "        N_y = Y.shape[0]\n",
    "    \n",
    "    # Number of observations\n",
    "    T = Z.shape[1]\n",
    "    \n",
    "    # Beta coefficient \n",
    "    Beta_hat = Y@Z.T@np.linalg.pinv((Z@Z.T))\n",
    "    \n",
    "    # Disturbance matrix\n",
    "    e_hat = Y - Beta_hat@Z\n",
    "    \n",
    "    # Residual covariance matrix\n",
    "    Sigma_hat = (e_hat@e_hat.T) / T\n",
    "    \n",
    "    # Inverse of information matrix\n",
    "    Iinv = np.kron(np.linalg.pinv(Z@Z.T), Sigma_hat)\n",
    "\n",
    "    # Standard error of beta \n",
    "    std_err = np.sqrt(np.diagonal(Iinv)).reshape(N_z, N_y).T\n",
    "    \n",
    "    # Test statistic\n",
    "    t_Stats = np.divide(Beta_hat, std_err)\n",
    "    \n",
    "    # P value\n",
    "    P_value = 2 * norm.sf(np.abs(t_Stats))\n",
    "    \n",
    "    if not isinstance(Sigma_hat, np.ndarray):\n",
    "        AIC = SC = None\n",
    "    else:\n",
    "        k = N_z * N_y\n",
    "        # AIC\n",
    "        AIC = np.log(np.linalg.det(Sigma_hat)) + 2 * k / T\n",
    "        # SC\n",
    "        SC = np.log(np.linalg.det(Sigma_hat)) + k / T * np.log(T)  \n",
    "    \n",
    "    ols = {'Estimates': Beta_hat,\n",
    "           'Std. Err': std_err,\n",
    "           't-Statistic': t_Stats,\n",
    "           'Pr(>|t|)': P_value,\n",
    "           'AIC': AIC,\n",
    "           'SC': SC,\n",
    "           'Residuals': e_hat\n",
    "           }\n",
    "    \n",
    "    return ols\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAR():\n",
    "    def __init__(self, X, p):\n",
    "        \"\"\"\n",
    "        Vector Autoregression model with lag p in the matrix form\n",
    "        \n",
    "        Input:\n",
    "            X: explanatory variables (each column is a time series variable)\n",
    "            p: number of lags\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X\n",
    "        self.p = p\n",
    "\n",
    "        # Number of variables\n",
    "        n = len(self.X.columns)\n",
    "\n",
    "        # Labels\n",
    "        self.label = list(self.X.columns)\n",
    "\n",
    "        # Explanatory matrix\n",
    "        Z = Explanatory(self.X, self.p)\n",
    "        \n",
    "        # Dependent matrix\n",
    "        Y = self.X[self.p:].values.T\n",
    "\n",
    "        # OLS result\n",
    "        self.ols = OLS(Z, Y)\n",
    "        \n",
    "        # Stability condition - eigenvalues\n",
    "        self.Lambda = dict.fromkeys(range(1, self.p+1))\n",
    "        for i in range(1, self.p+1):\n",
    "            B_p = self.ols['Estimates'][:, 1 + (i-1)*n : 1 + i*n]\n",
    "            eigenvalues, _ = np.linalg.eig(B_p)\n",
    "            self.Lambda[i] = abs(eigenvalues)\n",
    "            \n",
    "    def Estimation(self):\n",
    "        \"\"\"\n",
    "        Estimation table of the OLS regression\n",
    "\n",
    "        Output:\n",
    "             For every variable in the VAR model, the table contains: \n",
    "             Estimates: beta coefficient\n",
    "             Std. Err: standard error \n",
    "             t-Statistic: test statistic\n",
    "             Pr(>|t|): p value\n",
    "        \"\"\"\n",
    "        # Get the estimation result\n",
    "        Beta = self.ols['Estimates']\n",
    "        std_err = self.ols['Std. Err']\n",
    "        t_Stats = self.ols['t-Statistic']\n",
    "        P_value = self.ols['Pr(>|t|)']\n",
    "        \n",
    "        # Construct the table\n",
    "        table_header = ['Label', 'Statistics', 'Const']\n",
    "        table_data = []\n",
    "        for i in range(1, self.p + 1):\n",
    "            table_header += [key + '(-' + str(i)+ ')' for key in self.label]\n",
    "        for i in range(len(self.label)):\n",
    "            table_data.append([self.label[i] , 'Estimates'] + ['{:.4f}'.format(item) for item in Beta[i]])\n",
    "            table_data.append([self.label[i] , 'Std. Err'] + ['{:.4f}'.format(item) for item in std_err[i]])\n",
    "            table_data.append([self.label[i] , 't-Statistic'] + ['{:.4f}'.format(item) for item in t_Stats[i]])\n",
    "            table_data.append([self.label[i] , 'Pr(>|t|)'] + ['{:.4f}'.format(item) for item in P_value[i]])\n",
    "        estimation_table = pd.DataFrame(table_data, columns=table_header)\n",
    "        return estimation_table\n",
    "        \n",
    "    def AIC_SC(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function is for the optimal lag selection based on AIC and SC.\n",
    "        \n",
    "        prt = True: output a table of AIC and SC for each lag p>=1 (default)\n",
    "        \n",
    "        prt = False: output the lag p, AIC and SC values\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get the AIC and SC\n",
    "        AIC = self.ols['AIC']\n",
    "        SC = self.ols['SC']\n",
    "        \n",
    "        # Print the table\n",
    "        if prt:\n",
    "            table_header = ['Lag', 'AIC', 'SC']\n",
    "            table_data = [[str(self.p), '{:.4f}'.format(AIC), '{:.4f}'.format(SC)]]\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        else:\n",
    "            return [self.p, AIC, SC]\n",
    "    \n",
    "    def Stability(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function is for stability check.\n",
    "\n",
    "        prt = True: output a table of the eigenvalues of each relationship matrix and the corresponding stability result (default)\n",
    "        \n",
    "        prt = False: output the overall stability result for the lag p\n",
    "        \"\"\"\n",
    "        \n",
    "        table_header = ['Lag p', 'Eigenvalue', 'Modulus', 'Stable']\n",
    "        table_data = []\n",
    "        \n",
    "        # Check the stability condition\n",
    "        stability = True\n",
    "        for i in range(1, self.p + 1):\n",
    "            for j in range(len(self.Lambda[i])):\n",
    "                modulus = self.Lambda[i][j]\n",
    "                if abs(modulus) >= 1:\n",
    "                    stability = False\n",
    "                if j==0:\n",
    "                    table_data.append([str(i)] + ['{:.4f}'.format(modulus), '{:.4f}'.format(abs(modulus)), abs(modulus) < 1])\n",
    "                else:\n",
    "                    table_data.append([' '] + ['{:.4f}'.format(modulus), '{:.4f}'.format(abs(modulus)), abs(modulus) < 1])\n",
    "        if prt:\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        else:      \n",
    "            return stability\n",
    "        \n",
    "    def Correlation(self):\n",
    "        \"\"\"\n",
    "        This function is for the residual correlation of the VAR model.\n",
    "        \n",
    "        Output: a series of pair correlation in descending order\n",
    "        \"\"\"\n",
    "        # Get the residuals\n",
    "        e_hat = self.ols['Residuals']\n",
    "        \n",
    "        # Residual correlation\n",
    "        e_corr = pd.DataFrame(e_hat.T, columns=self.label).corr()\n",
    "        \n",
    "        # return the pair correlation in descending order\n",
    "        return e_corr.stack().sort_values(ascending=False)[len(self.label)::2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(level, T):\n",
    "    \"\"\"\n",
    "    This function is used to calculate the estimated critical value of the ADF test for a given level and sample size.\n",
    "    \n",
    "    Input:\n",
    "        level: '1%', '5%', '10%'\n",
    "        T: sample size\n",
    "    \n",
    "    Output:\n",
    "        cv: estimated critical value for two time series with constant but no trend\n",
    "\n",
    "    Reference:\n",
    "    James G. MacKinnon (2010), Critical Values for Cointegration Tests\n",
    "    \"\"\"\n",
    "    \n",
    "    if level=='1%':\n",
    "        cv = -3.89644 - 10.9519/T - 22.527/T**2\n",
    "    elif level=='5%':\n",
    "        cv = -3.33613 - 6.1101/T - 6.823/T**2\n",
    "    elif level=='10%':\n",
    "        cv = -3.04445 - 4.2412/T - 2.72/T**2\n",
    "    else:\n",
    "        cv = False\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Engle_Granger():\n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        Engle-Granger two-step method\n",
    "         \n",
    "        Inputs:\n",
    "            X: explanatory variables (each column is a time series variable)\n",
    "            Y: dependent variable\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        # Explanatory matrix\n",
    "        Z = Explanatory(self.X, 0)\n",
    "        \n",
    "        # Dependent matrix\n",
    "        Y_ = self.Y.values.T\n",
    "        \n",
    "        # OLS result\n",
    "        self.ols = OLS(Z, Y_)\n",
    "        self.Beta_hat = self.ols['Estimates']\n",
    "        self.e_hat = pd.DataFrame(self.ols['Residuals'], index=self.X.index) \n",
    "        \n",
    "    def OLS2(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function gives the results of estimating parameters and corresponding statistics for OLS.\n",
    "\n",
    "        prt=True: output a table which contains beta coefficient, standard error, test statistic and p value\n",
    "        \n",
    "        prt=False: output the beta coefficients\n",
    "        \"\"\"\n",
    "        \n",
    "        table_header = ['', 'Const']\n",
    "        table_data = []\n",
    "        \n",
    "        for i in range(1, len(self.Beta_hat)):\n",
    "            table_header += ['Beta_'+str(i)]\n",
    "        table_data.append(['Estimates'] + list(self.Beta_hat))\n",
    "        table_data.append(['Std. Err'] + list(chain.from_iterable(self.ols['Std. Err'])))\n",
    "        table_data.append(['t-Statistic'] + list(chain.from_iterable(self.ols['t-Statistic'])))\n",
    "        table_data.append(['Pr(>|t|)'] + list(chain.from_iterable(self.ols['Pr(>|t|)'])))\n",
    "        \n",
    "        if prt:\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        else:\n",
    "            return self.Beta_hat\n",
    "    \n",
    "    def ADF(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function gives the results of estimating parameters and corresponding statistics for ADF test.\n",
    "\n",
    "        prt=True: output a table which contains critical value, beta coefficient, standard error, test statistic and p value\n",
    "        \n",
    "        prt=False: output the OLS() result\n",
    "        \"\"\"\n",
    "        \n",
    "        # Delta residual\n",
    "        delta_e = self.e_hat.diff().dropna()\n",
    "        \n",
    "        # Desidual of lag 1\n",
    "        e_lag = self.e_hat.shift(1).dropna()\n",
    "\n",
    "        # Delta residual of lag 1\n",
    "        delta_e_lag = delta_e.shift(1).dropna()\n",
    "        \n",
    "        # ADF test data\n",
    "        adf_data = pd.concat([e_lag, delta_e_lag, delta_e], axis=1).dropna()\n",
    "        adf_data.columns = ['e_lag', 'delta_e_lag', 'delta_e']\n",
    "        \n",
    "        # Explanatory matrix with constant\n",
    "        X_e = Explanatory(adf_data[['e_lag', 'delta_e_lag']], 0)\n",
    "        \n",
    "        # Dependent matrix\n",
    "        Y_e = adf_data['delta_e'].values.T\n",
    "        \n",
    "        result = OLS(X_e, Y_e)\n",
    "\n",
    "        table_header = ['', 'Const', 'φ', 'φ_1']\n",
    "        table_data = []\n",
    "        table_data.append(['Estimates'] + list(result['Estimates']))\n",
    "        table_data.append(['Std. Err'] + list(chain.from_iterable(result['Std. Err'])))\n",
    "        table_data.append(['t-Statistic'] + list(chain.from_iterable(result['t-Statistic'])))\n",
    "        table_data.append(['Pr(>|t|)'] + list(chain.from_iterable(result['Pr(>|t|)'])))\n",
    "        \n",
    "        # Sample size\n",
    "        T = len(adf_data)\n",
    "        \n",
    "        if prt:\n",
    "            print('CV:','\\n 1%: ', CV('1%', T), '\\n 5%: ', CV('5%', T), '\\n 10%: ', CV('10%', T))\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def EC(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function is used to do error correction for step 2 in Engle-Granger procedure.\n",
    "\n",
    "        prt=True: output a table which contains beta coefficient, standard error, test statistic and p value\n",
    "\n",
    "        prt=False: output the OLS() result\n",
    "        \"\"\"\n",
    "        \n",
    "        # Delta price B\n",
    "        delta_X = self.X.diff().dropna()\n",
    "        \n",
    "        # Delta price A\n",
    "        delta_Y = self.Y.diff().dropna()\n",
    "        \n",
    "        # Residual of lag 1\n",
    "        e_lag = self.e_hat.shift(1).dropna()\n",
    "     \n",
    "        # Dependent matrix\n",
    "        Y_ = delta_Y.values.T\n",
    "        \n",
    "        # Explanatory matrix without constant\n",
    "        Z = pd.concat([delta_X, e_lag], axis=1).values.T\n",
    "        \n",
    "        result = OLS(Z, Y_)\n",
    "        \n",
    "        table_header = ['', 'φ', '-(1-α)']\n",
    "        table_data = []\n",
    "        table_data.append(['Estimates'] + list(result['Estimates']))\n",
    "        table_data.append(['Std. Err'] + list(chain.from_iterable(result['Std. Err'])))\n",
    "        table_data.append(['t-Statistic'] + list(chain.from_iterable(result['t-Statistic'])))\n",
    "        table_data.append(['Pr(>|t|)'] + list(chain.from_iterable(result['Pr(>|t|)'])))\n",
    "        if prt:\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OU():\n",
    "    def __init__(self, e_hat):\n",
    "        \"\"\"\n",
    "        Fit the stationary spread to the Ornstein-Uhlenbeck Process.\n",
    "        \n",
    "        Input:\n",
    "            e_hat: the stationary residual\n",
    "        \"\"\"\n",
    "        self.e = e_hat\n",
    "        \n",
    "    def fit(self, prt = True):\n",
    "        \"\"\"\n",
    "        This function is used to fit the residual to AR(1).\n",
    "\n",
    "        prt = True: output the regression result containing the beta coefficient, standard error, test statistic and p value (default)\n",
    "\n",
    "        prt = False: do not output the regression result\n",
    "        \"\"\"\n",
    "        \n",
    "        # Residual of lag 1\n",
    "        e_lag = self.e.shift(1).dropna()\n",
    "\n",
    "        # Dependent matrix\n",
    "        Y = self.e[1:].values.T\n",
    "\n",
    "        # Explanatory matrix\n",
    "        Z = Explanatory(e_lag, 0)\n",
    "\n",
    "        # Fitting\n",
    "        result = OLS(Z, Y)\n",
    "\n",
    "        # Beta coefficients\n",
    "        self.C = list(result['Estimates'])[0]\n",
    "        self.B = list(result['Estimates'])[1]\n",
    "\n",
    "        # SSE\n",
    "        self.SSE = result['Residuals']@result['Residuals'].T\n",
    "        \n",
    "        table_header = ['', 'C', 'B']\n",
    "        table_data = []\n",
    "        table_data.append(['Estimates'] + list(result['Estimates']))\n",
    "        table_data.append(['Std. Err'] + list(chain.from_iterable(result['Std. Err'])))\n",
    "        table_data.append(['t-Statistic'] + list(chain.from_iterable(result['t-Statistic'])))\n",
    "        table_data.append(['Pr(>|t|)'] + list(chain.from_iterable(result['Pr(>|t|)'])))\n",
    "        \n",
    "        if prt:\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        \n",
    "    def mean_reversion(self, prt=True):\n",
    "        \"\"\"\n",
    "        This function is used to compute the mean reverting parameters of the stationary spread.\n",
    "        \n",
    "        prt = True: output the mean reversion speed, equilibirum level, standard deviation of the stationary spread, standard deviation of the OU process, halflife and halflife in days (default)\n",
    "       \n",
    "        prt = False: do not output the mean reversion parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # Time step\n",
    "        tau = 1/252\n",
    "        \n",
    "        # Mean reversion speed\n",
    "        theta = - np.log(self.B)/tau\n",
    "        \n",
    "        # Equilibrium level\n",
    "        mu_e = self.C / (1 - self.B)\n",
    "        \n",
    "        # Standard deviation of the stationary spread\n",
    "        sigma_eq = np.sqrt(self.SSE*tau / (1 - np.exp(-2*theta*tau)))\n",
    "        \n",
    "        # Standard deviation of the OU process\n",
    "        sigma_ou = sigma_eq * np.sqrt(2*theta)\n",
    "        \n",
    "        # Halflife\n",
    "        tau_tilde = np.log(2)/theta\n",
    "\n",
    "        # Halflife in days\n",
    "        tau_tilde_days = tau_tilde/tau\n",
    "        \n",
    "        table_header = ['Parameters', 'Values']\n",
    "        table_data = [['θ', theta],\n",
    "                      ['μ_e', mu_e],\n",
    "                      ['σ_eq', sigma_eq],\n",
    "                      ['σ_ou', sigma_ou],\n",
    "                      ['Halflife', tau_tilde],\n",
    "                      ['Halflife in days', tau_tilde_days]]\n",
    "        if prt:\n",
    "            print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        return (mu_e, sigma_eq, tau_tilde_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pairs_trading():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This class is used to do the pairs trading and backtesting on the given assets.\n",
    "        \"\"\"\n",
    "\n",
    "    ################################# Trading ########################################\n",
    "    def fitting(self, X, Y):\n",
    "        \"\"\"\n",
    "        This function is used to fit the spread to the OU process and get the parameters.\n",
    "        \n",
    "        Input:\n",
    "            X : explanatory variable\n",
    "            Y : dependent variable\n",
    "                \n",
    "        Output:\n",
    "            Equilibrium level (mu_e)\n",
    "            Standard deviation of the stationary spread (sigma_eq)\n",
    "            Halflife in days (tau_tilde_days)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        EG = Engle_Granger(self.X, self.Y)\n",
    "        \n",
    "        # Beta coefficients\n",
    "        beta = EG.OLS2(prt=False)\n",
    "        self.est_const = beta[0]\n",
    "        self.est_beta = beta[1]\n",
    "        \n",
    "        # Loading β_coint\n",
    "        self.loading = np.array([1, - beta[1]])\n",
    "        \n",
    "        # Residuals\n",
    "        e_hat = self.Y - beta[1]*self.X - beta[0]\n",
    "        \n",
    "        del EG\n",
    "        \n",
    "        ou = OU(e_hat)\n",
    "        ou.fit(prt=False)\n",
    "        \n",
    "        # Equilibrium level, standard deviation of the stationary spread, halflife in days\n",
    "        self.mu_e, self.sigma_eq, self.halflife = ou.mean_reversion(prt=False)\n",
    "       \n",
    "        del ou\n",
    "        \n",
    "    def trading(self, data, explanatory_label, dependent_label, Z, Z_e=0, Z_s=4, spread=0, long_cost=0, short_cost=0):\n",
    "        \"\"\"\n",
    "        This function is for the trading on the given assets.\n",
    "           \n",
    "        Input:\n",
    "            data: dataFrame with the explanatory and dependend trading assets \n",
    "                \n",
    "            explanatory_label: name of the explanatory asset\n",
    "            \n",
    "            dependent_label: name of the dependent trading asset \n",
    "                \n",
    "            Z: entry threshold\n",
    "            \n",
    "            Z_e: exit threshold when the residual reverts back to a value around the mu_e (0 by default)\n",
    "            \n",
    "            Z_s: exit threshold to stop loss when the residual goes too far away from the mu_e (4 by default, almost impossible to reach)\n",
    "                \n",
    "            spread: Bid-ask spread of the trading assets (0 by default). Assume that the spread is the same for both assets on the same day and the price is the mid price of the bid and ask price.\n",
    "            \n",
    "            long_cost: transaction cost in fraction of the trading amount when long the loading (0 by default)\n",
    "                \n",
    "            short_cost: transaction cost in fraction of the trading amount when short the loading (0 by default)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Record trading information\n",
    "        trading_book = data.copy(deep=True)\n",
    "        \n",
    "        # Dependent asset\n",
    "        B = data[dependent_label]\n",
    "        \n",
    "        # Explanatory asset\n",
    "        A = data[explanatory_label]\n",
    "        \n",
    "        ##################### Spread's Influence ##################### \n",
    "        # Price of long B (ask price of B)\n",
    "        trading_book['ask_price_'+ dependent_label] = B + spread/2\n",
    "        \n",
    "        # Price of short B (bid price of B)\n",
    "        trading_book['bid_price_'+ dependent_label] = B - spread/2\n",
    "        \n",
    "        # Price of long A (ask price of A)\n",
    "        trading_book['ask_price_'+ explanatory_label] = A + spread/2\n",
    "        \n",
    "        # Price of short A (bid price of A)\n",
    "        trading_book['bid_price_'+ explanatory_label] = A - spread/2\n",
    "        \n",
    "        # Fitted B based on A\n",
    "        B_fitted = self.est_const + self.est_beta * A\n",
    "        \n",
    "        # Residual of B and predicted B\n",
    "        trading_book['Residual'] = B - B_fitted\n",
    "        \n",
    "        # Verify the values of Z_e and Z_s\n",
    "        if Z_e >= Z:\n",
    "            print('Z_e should be smaller than Z!')\n",
    "            return\n",
    "        if Z_s <= Z:\n",
    "            print('Z_s should be bigger than Z!')\n",
    "            return\n",
    "        \n",
    "        # Entry threshold\n",
    "        entry_upper = self.mu_e + Z*self.sigma_eq\n",
    "        entry_lower = self.mu_e - Z*self.sigma_eq\n",
    "        \n",
    "        # Exit threshold\n",
    "        exit_upper = self.mu_e + Z_e*self.sigma_eq\n",
    "        exit_lower = self.mu_e - Z_e*self.sigma_eq\n",
    "        \n",
    "        # Stop loss threshold\n",
    "        stop_upper = self.mu_e + Z_s*self.sigma_eq\n",
    "        stop_lower = self.mu_e - Z_s*self.sigma_eq\n",
    "        \n",
    "        # Total number of trading \n",
    "        num_of_trades = 0\n",
    "        \n",
    "        # Total PL\n",
    "        PL = 0\n",
    "        \n",
    "        # Entry price of B\n",
    "        in_price_B = []\n",
    "        \n",
    "        # Entry price of A\n",
    "        in_price_A = []\n",
    "        \n",
    "        # Exit price of B\n",
    "        ex_price_B = []\n",
    "        \n",
    "        # Exit price of A\n",
    "        ex_price_A = []\n",
    "        \n",
    "        # Entry dates\n",
    "        entry_dates = []\n",
    "        \n",
    "        # Exit dates (including exits of stopping loss)\n",
    "        exit_dates = []\n",
    "        \n",
    "        # Trading P&L\n",
    "        PL_trade = []\n",
    "        \n",
    "        # Days of each trade\n",
    "        days_trade = []\n",
    "        \n",
    "        ########################## Generate the Position Status ############################\n",
    "        # Position status initialised to be 0\n",
    "        Status = len(trading_book) * [0]\n",
    "        \n",
    "        for idx in range(1, len(trading_book.index)):\n",
    "            ######################### When Residual Goes Down #########################\n",
    "            # If the residual cross the stop loss upper bound - do nothing\n",
    "            if trading_book['Residual'][idx-1] > stop_upper and trading_book['Residual'][idx] <= stop_upper:\n",
    "                Status[idx] = Status[idx-1]\n",
    "                \n",
    "            # If the residual cross the entry upper bound - do nothing    \n",
    "            elif trading_book['Residual'][idx-1] > entry_upper and trading_book['Residual'][idx] <= entry_upper:\n",
    "                Status[idx] = Status[idx-1]\n",
    "                \n",
    "            # If the residual cross the exit upper bound - exit from the current status\n",
    "            elif trading_book['Residual'][idx-1] > exit_upper and trading_book['Residual'][idx] <= exit_upper:\n",
    "                Status[idx] = 0\n",
    "            \n",
    "            # If the residual cross the exit lower bound - do nothing \n",
    "            elif trading_book['Residual'][idx-1] > exit_lower and trading_book['Residual'][idx] <= exit_lower:\n",
    "                Status[idx] = Status[idx-1]\n",
    "        \n",
    "            # If the residual cross the entry lower bound - long the loading\n",
    "            elif trading_book['Residual'][idx-1] > entry_lower and trading_book['Residual'][idx] <= entry_lower:\n",
    "                Status[idx] = 1\n",
    "                \n",
    "            # If the residual cross the stop loss lower bound - exit from the current status\n",
    "            elif trading_book['Residual'][idx-1] > stop_lower and trading_book['Residual'][idx] <= stop_lower:\n",
    "                Status[idx] = 0\n",
    "            \n",
    "            ######################### When Residual Goes Up #########################\n",
    "            # If the residual cross the stop loss lower bound - do nothing\n",
    "            elif trading_book['Residual'][idx-1] < stop_lower and trading_book['Residual'][idx] >= stop_lower:\n",
    "                Status[idx] = Status[idx-1]\n",
    "            \n",
    "            # If the residual cross the entry lower bound - do nothing\n",
    "            elif trading_book['Residual'][idx-1] < entry_lower and trading_book['Residual'][idx] >= entry_lower:\n",
    "                Status[idx] = Status[idx-1]\n",
    "            \n",
    "            # If the residual cross the exit lower bound - exit from the current status\n",
    "            elif trading_book['Residual'][idx-1] < exit_lower and trading_book['Residual'][idx] >= exit_lower:\n",
    "                Status[idx] = 0\n",
    "            \n",
    "            # If the residual cross the exit upper bound - do nothing\n",
    "            elif trading_book['Residual'][idx-1] < exit_upper and trading_book['Residual'][idx] >= exit_upper:\n",
    "                Status[idx] = Status[idx-1]\n",
    "            \n",
    "            # If the residual cross the entry upper bound - short the loading    \n",
    "            elif trading_book['Residual'][idx-1] < entry_upper and trading_book['Residual'][idx] >= entry_upper:\n",
    "                Status[idx] = -1\n",
    "\n",
    "            # If the residual cross the stop loss upper bound - exit from the current status\n",
    "            elif trading_book['Residual'][idx-1] < stop_upper and trading_book['Residual'][idx] >= stop_upper:\n",
    "                Status[idx] = 0\n",
    "                \n",
    "            # For other cases - do nothing\n",
    "            else:\n",
    "                Status[idx] = Status[idx-1]\n",
    "\n",
    "        # If status is not 0 in the last days, assume that this trade was not did and set the latest non-zero squences to 0\n",
    "        i = 1\n",
    "        while(Status[-i] != 0):\n",
    "            Status[-i] = 0\n",
    "            i = i+1\n",
    "\n",
    "        # Position status\n",
    "        trading_book['Status'] = Status\n",
    "        \n",
    "        ############################## Generate Trading Signal ##############################\n",
    "        # Trading signal: 1 or 2 (long the loading), -1 or -2 (short the loading)\n",
    "        # 2 means exit from the current position and entry in the opposite position on the same day\n",
    "        trading_book['Signal'] = trading_book['Status'].diff().fillna(0)\n",
    "        \n",
    "        ############################## Entry or Exit  ##############################\n",
    "        # if Signal = 1 (long the loading) and Status=1 (in long position), then it is an entry\n",
    "        # if Signal = -1 (short the loading) and Status=-1 (in short position), then it is an entry\n",
    "        # if Signal = 1 (long the loading) and Status=0 (in clear position), then it is an exit\n",
    "        # if Signal = -1 (short the loading) and Status=0 (in clear position), then it is an exit\n",
    "        trading_book['Entry'] = trading_book['Signal'] * trading_book['Status']\n",
    "        trading_book['Exit'] = [0] * len(trading_book['Status']) \n",
    "        trading_book.loc[(trading_book['Signal']!=0) & (trading_book['Status']==0),'Exit'] = 1\n",
    "       \n",
    "        # if Signal = 2 or -2, then entry and exit on the same day\n",
    "        trading_book.loc[abs(trading_book['Signal'])==2, 'Entry'] = 1\n",
    "        trading_book.loc[abs(trading_book['Signal'])==2, 'Exit'] = 1\n",
    "        \n",
    "        ############################## Trading Price of the Portfolio ##############################\n",
    "        # Considering long and short costs: (1+long_cost) for long, (1-short_cost) for short\n",
    "        # Portfolio trading price: 1 B and - est_beta A\n",
    "        # Long portfolio = 1 ask_price_B*(1+long_cost)  - est_beta bid_price_A*(1-short_cost)\n",
    "        trading_book['ask_price_port'] = \\\n",
    "            trading_book['ask_price_'+dependent_label] * (1 + long_cost) - self.est_beta * trading_book['bid_price_'+explanatory_label] * (1 - short_cost)\n",
    "        \n",
    "        # Short portfolio = -[-1 bid_price_B*(1-shortcost) + est_beta bid_price_A*(1+longcost)]\n",
    "        trading_book['bid_price_port'] = \\\n",
    "            - (- trading_book['bid_price_'+dependent_label] * (1-short_cost) + self.est_beta * trading_book['ask_price_'+explanatory_label] * (1 + long_cost))\n",
    "        \n",
    "        # Portfolio trading price: bid_price_port when we are at long position (Status=1), for other cases ask_price_port\n",
    "        trading_book['price_port'] = trading_book['ask_price_port']\n",
    "        trading_book.loc[trading_book['Status']==1,'price_port'] = trading_book.loc[trading_book['Status']==1,'bid_price_port']\n",
    "        \n",
    "        # Too big value of spread/transaction cost will make the portfolio price negative, which is not reasonable\n",
    "        if len(trading_book[trading_book['price_port']<0])>0:\n",
    "            print('Too much spread or transaction costs make the portfolio price negative!')\n",
    "            trading_book['price_port'].iplot(title = 'Portfolio Price with Negative Value', legend=False)\n",
    "            return\n",
    "        \n",
    "        ################################## P&L ###################################        \n",
    "        trading_book['log_ret_port'] = np.log(trading_book['price_port']).diff()\n",
    "        trading_book = trading_book.dropna()\n",
    "       \n",
    "        # daily P&L\n",
    "        trading_book['P&L'] = trading_book['log_ret_port']*trading_book['Status']\n",
    "        \n",
    "        ############################ Result Summary #############################\n",
    "        # Total number of trades\n",
    "        num_of_trades = abs(trading_book['Signal']).sum()/2\n",
    "       \n",
    "        # Total P&L\n",
    "        PL = trading_book['P&L'].sum()\n",
    "        \n",
    "        # Entry dates\n",
    "        entry_dates = list(trading_book[trading_book['Entry']==1].index)\n",
    "        \n",
    "        # Exit dates (including exits of stopping loss)\n",
    "        exit_dates = list(trading_book[trading_book['Exit']==1].index)\n",
    "        \n",
    "        # Entry price of B and A (not including transaction cost)\n",
    "        for date in entry_dates:\n",
    "            if trading_book.loc[date, 'Signal'] > 0:   \n",
    "                ################ long the portfolio = long B + short A ################\n",
    "                # Entry price of B\n",
    "                in_price_B.append(trading_book.loc[date ,'ask_price_'+dependent_label])\n",
    "                \n",
    "                # Entry price of A\n",
    "                in_price_A.append(trading_book.loc[date ,'bid_price_'+explanatory_label])\n",
    "            elif trading_book.loc[date, 'Signal'] < 0:\n",
    "                ################ short the portfolio = short B + long A ################\n",
    "                # Entry price of B\n",
    "                in_price_B.append(trading_book.loc[date ,'bid_price_'+dependent_label])\n",
    "               \n",
    "                # Entry price of A\n",
    "                in_price_A.append(trading_book.loc[date ,'ask_price_'+explanatory_label])\n",
    "        \n",
    "        # Exit prices of B and A (not including transaction cost)\n",
    "        for date in exit_dates:\n",
    "            if trading_book.loc[date, 'Signal'] > 0:   \n",
    "                ################ long the portfolio = long B + short A ################\n",
    "                # Exit prices of B\n",
    "                ex_price_B.append(trading_book.loc[date ,'ask_price_'+dependent_label])\n",
    "                \n",
    "                # Exit prices of A\n",
    "                ex_price_A.append(trading_book.loc[date ,'bid_price_'+explanatory_label])\n",
    "            elif trading_book.loc[date, 'Signal'] < 0:\n",
    "                ################ short the portfolio = short B + long A ################\n",
    "                # Exit prices of B\n",
    "                ex_price_B.append(trading_book.loc[date ,'bid_price_'+dependent_label])\n",
    "                \n",
    "                # Exit prices of A\n",
    "                ex_price_A.append(trading_book.loc[date ,'ask_price_'+explanatory_label])\n",
    "\n",
    "        for i in range(len(entry_dates)):\n",
    "            # Trading P&L\n",
    "            PL_trade.append(trading_book.loc[entry_dates[i]:exit_dates[i], 'P&L'].sum())\n",
    "            \n",
    "            # Average days of trade\n",
    "            days_trade.append((datetime.datetime.strptime(exit_dates[i].strftime('%Y-%m-%d'), '%Y-%m-%d').date() \n",
    "                               - datetime.datetime.strptime(entry_dates[i].strftime('%Y-%m-%d'), '%Y-%m-%d').date()).days)\n",
    "        \n",
    "        # Average return per trade\n",
    "        if num_of_trades != 0:\n",
    "            PL_per_trade = np.mean(PL_trade)\n",
    "        else:\n",
    "            PL_per_trade = 'No Trade'\n",
    "        \n",
    "        # Sharpe Ratio with risk-free interest = 0\n",
    "        self.SR = (252*trading_book['P&L'].mean()) / (np.sqrt(252)*trading_book['P&L'].std())\n",
    "        \n",
    "        self.summary = {\n",
    "                      'Trading Book': trading_book,\n",
    "                      'Cummulative Returns': PL,\n",
    "                      'Annualised Return': PL * 252/len(trading_book),\n",
    "                      'Total Number of Trades': num_of_trades,\n",
    "                      'Return Per Trade': PL_trade,\n",
    "                      'Average Return Per Trade': PL_per_trade,\n",
    "                      'Days Per Trade': days_trade,\n",
    "                      'Entry Dates': entry_dates,\n",
    "                      'Exit Dates': exit_dates,\n",
    "                      'Entry Prices for '+explanatory_label: in_price_A,\n",
    "                      'Entry Prices for '+dependent_label: in_price_B, \n",
    "                      'Exit Prices for '+explanatory_label: ex_price_A,\n",
    "                      'Exit Prices for '+dependent_label: ex_price_B, \n",
    "                      'Entry Upper Bound': entry_upper,\n",
    "                      'Entry Lower Bound': entry_lower,\n",
    "                      'Exit Upper Bound': exit_upper,\n",
    "                      'Exit Lower Bound': exit_lower,\n",
    "                      'Stop Upper Bound': stop_upper,\n",
    "                      'Stop Lower Bound': stop_lower\n",
    "        }\n",
    "        return self.summary\n",
    "    \n",
    "    ######################################### Backtesting #########################################\n",
    "    def backtest(self, MADD=1.0, output=True):\n",
    "        \"\"\"\n",
    "        This function is for the backtesting of the pairs trading strategy.\n",
    "            \n",
    "        Input:\n",
    "            MADD: maximum acceptable drawdown of the trader, from 0 to 1 (1.0 by default)\n",
    "                \n",
    "            output: whether to print the table and plots (True by default)\n",
    "             \n",
    "        Output:\n",
    "             Table:  \n",
    "                1. Start Date\n",
    "                2. End Date\n",
    "                3. Total Number of Trades\n",
    "                4. Average Trades Per Year\n",
    "                5. Average Trading Days (Calender)\n",
    "                6. Annual Return\n",
    "                7. Cumulative Returns\n",
    "                8. Average Return Per Trade\n",
    "                9. Annual Volatility\n",
    "                10. Annual Alpha\n",
    "                11. Beta\n",
    "                12. Information Ratio\n",
    "                13. Sharpe Ratio\n",
    "                14. Max Drawdown\n",
    "                15. Daily Value at Risk (99%)\n",
    "                16. Drawdown Control\n",
    "            \n",
    "             Plots: \n",
    "                1. Bid, Ask and Trading price of portfolio\n",
    "                2. Residual\n",
    "                3. Cumulative Returns\n",
    "                4. Rolling Volatility\n",
    "                5. Rolling Beta\n",
    "                6. Rolling Alpha\n",
    "                7. Rolling Information Ratio                         \n",
    "                8. Rolling Sharpe Ratio                     \n",
    "                9. Underwater Plot\n",
    "                10. Daily VaR 99%\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load the market price\n",
    "        mkt_data = pd.read_csv('commodities+SP500.csv', index_col='Date')[['S&P500']]\n",
    "        mkt_data['Market Return'] = np.log(mkt_data['S&P500']).diff().dropna()\n",
    "        \n",
    "        # Backtest book\n",
    "        backtest_book = pd.concat([self.summary['Trading Book']['P&L'], mkt_data['Market Return']], axis=1).dropna()\n",
    "        \n",
    "        ##################### Rolling volatility ####################\n",
    "        def get_vol(df):\n",
    "            if np.std(df)!=0:\n",
    "                # annualised Sharpe Ratio\n",
    "                return np.sqrt(252)*np.std(df)\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        backtest_book['Volatility 6M'] = backtest_book['P&L'].rolling(126).apply(get_vol, raw=False)\n",
    "\n",
    "        ################# Rolling Alpha, Beta, Information Ratio ################\n",
    "        def get_alpha_beta(window, period, mkt_ret=backtest_book['Market Return'], strategy_ret=backtest_book['P&L']):\n",
    "            alpha = [0]*len(backtest_book)\n",
    "            beta = [0]*len(backtest_book)\n",
    "            ir = [0]*len(backtest_book)\n",
    "            \n",
    "            for i in range(len(backtest_book)-window):\n",
    "                # Dependent vector\n",
    "                strategy_ret_mat = (strategy_ret.iloc[i:i+window]).values.T\n",
    "                \n",
    "                # Explanatory matrix\n",
    "                mkt_ret_mat = Explanatory((mkt_ret.iloc[i:i+window]), 0)\n",
    "                \n",
    "                # Regress\n",
    "                ols = OLS(mkt_ret_mat, strategy_ret_mat)\n",
    "                coef = ols['Estimates']\n",
    "                sigma = np.std(ols['Residuals'])\n",
    "                \n",
    "                # Annualised alpha\n",
    "                alpha[i+window] = coef[0]*252\n",
    "                \n",
    "                # Beta\n",
    "                beta[i+window] = coef[1]\n",
    "                \n",
    "                # Annualised information ratio\n",
    "                if sigma!=0:\n",
    "                    ir[i+window] = (252*coef[0])/(np.sqrt(252)*sigma)\n",
    "                else:\n",
    "                    ir[i+window] = 0\n",
    "           \n",
    "            backtest_book['Alpha '+period] = alpha\n",
    "            backtest_book['Beta '+period] = beta\n",
    "            backtest_book['Information Ratio (IR) '+period] = ir\n",
    "            return \n",
    "        \n",
    "        get_alpha_beta(window=126, period='6M')\n",
    "            \n",
    "        ################# Rolling Sharpe Ratio ################\n",
    "        def get_sharpe_ratio(df):\n",
    "            if np.std(df)!=0 and np.mean(df)!=0:\n",
    "                # Annualised Sharpe Ratio\n",
    "                return (252*np.mean(df))/(np.sqrt(252)*np.std(df))\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        backtest_book['SR 6M'] = backtest_book['P&L'].rolling(126).apply(get_sharpe_ratio, raw=False)\n",
    "        \n",
    "        ####################### Drawdown ########################\n",
    "        def get_drawdown(array):\n",
    "            # Initial cash is 1, and transform log return into cash\n",
    "            array = np.exp(array)*1\n",
    "            drawdowns = []\n",
    "            max_so_far = array[0]\n",
    "            for i in range(len(array)):\n",
    "                if array[i] >= max_so_far:\n",
    "                    drawdown = 0\n",
    "                    drawdowns.append(drawdown)\n",
    "                    max_so_far = array[i]\n",
    "                else:\n",
    "                    drawdown = (max_so_far - array[i])/max_so_far\n",
    "                    drawdowns.append(drawdown)\n",
    "            return drawdowns\n",
    "\n",
    "        backtest_book['Drawdown'] = get_drawdown(backtest_book['P&L'].cumsum())\n",
    "        \n",
    "        ####################### VaR at 99% ########################\n",
    "        def get_VaR(array):\n",
    "            mean = np.mean(array)\n",
    "            std_dev = np.std(array)\n",
    "            if std_dev!=0:\n",
    "                VaR_99 = stats.norm.ppf(1-0.99, mean, std_dev)\n",
    "            else:\n",
    "                VaR_99 = 0\n",
    "            return VaR_99\n",
    "        \n",
    "        backtest_book['Daily VaR (99%)'] = backtest_book['P&L'].rolling(126).apply(get_VaR, raw=False)\n",
    "        \n",
    "        ####################### Drawdown Control ########################\n",
    "        control = []\n",
    "        for idx in backtest_book.index:\n",
    "            if np.isnan(backtest_book.loc[idx, 'Daily VaR (99%)']):\n",
    "                control.append(0)\n",
    "            else:\n",
    "                if (abs(backtest_book.loc[idx, 'Daily VaR (99%)']) + backtest_book.loc[idx, 'Drawdown']) <= MADD:\n",
    "                    control.append(0)\n",
    "                else: \n",
    "                    control.append(1)\n",
    "                    \n",
    "        if sum(control) == 0:\n",
    "            drawdown_control = 'True'\n",
    "        else:\n",
    "            drawdown_control = 'False'\n",
    "            \n",
    "        # If output is False, stops here and do not print and plot\n",
    "        if not output:\n",
    "            return\n",
    "        ############################### Print Info #######################################\n",
    "        table_header = ['', 'Backtest']\n",
    "        table_data = [['Start Date', backtest_book.index[0]],\n",
    "                      ['End Date', backtest_book.index[-1]],\n",
    "                      ['Total Number of Trades', self.summary['Total Number of Trades']],\n",
    "                      ['Average Trades Per Year', round(self.summary['Total Number of Trades']/len(self.summary['Trading Book'])*252, 2)],\n",
    "                      ['Average Trading Days (Calender)', round(sum(self.summary['Days Per Trade'])/len(self.summary['Days Per Trade']),2)],\n",
    "                      ['Annual Return', str(round(np.exp(self.summary['Annualised Return'])*100, 2))+'%'],\n",
    "                      ['Cumulative Returns', str(round(np.exp(self.summary['Cummulative Returns'])*100, 2))+'%'],\n",
    "                      ['Average Return Per Trade', str(round(np.exp(self.summary['Average Return Per Trade'])*100, 2))+'%'],\n",
    "                      ['Annual Volatility', str(round(backtest_book['Volatility 6M'].mean()*100, 2))+'%'],\n",
    "                      ['Annual Alpha', round(backtest_book['Alpha 6M'].mean(), 2)],\n",
    "                      ['Beta', round(backtest_book['Beta 6M'].mean(), 2)],\n",
    "                      ['Information Ratio', round(backtest_book['Information Ratio (IR) 6M'].mean(), 2)],\n",
    "                      ['Sharpe Ratio', round(backtest_book['SR 6M'].mean(), 2)],\n",
    "                      ['Max Drawdown', str(round(-backtest_book['Drawdown'].max()*100, 2))+'%'],\n",
    "                      ['Daily Value at Risk (99%)', str(round(backtest_book['Daily VaR (99%)'].mean()*100, 2))+'%'],\n",
    "                      ['Drawdown Control', drawdown_control]]\n",
    "        print(tabulate(table_data, headers=table_header, tablefmt='pipe'))\n",
    "        \n",
    "        ############################################ Plots ############################################\n",
    "        # 1. Bid, Ask and Trading price of portfolio\n",
    "        periods = []\n",
    "        for i in range(len(self.summary['Entry Dates'])):\n",
    "            periods.append({'x0':self.summary['Entry Dates'][i],'x1':self.summary['Exit Dates'][i],'color':'green','fill':True,'opacity':0.05})\n",
    "        self.summary['Trading Book'][['ask_price_port','bid_price_port', 'price_port']].iplot(title='Bid, Ask and Trading Prices of Portfolio',\n",
    "                                                                                              xTitle='Time', yTitle='Price', legend='top',\n",
    "                                                                                              vspan=periods)\n",
    "        \n",
    "        # 2. Residual\n",
    "        self.summary['Trading Book']['Residual'].iplot(title='Residual Movement', xTitle='Time', yTitle='Residual',\n",
    "                                                       width=2, vspan=periods, \n",
    "                                                       hline=[dict(y=self.summary['Exit Upper Bound'], color='blue', width=3, dash='dash'),\n",
    "                                                              dict(y=self.summary['Exit Lower Bound'], color='blue', width=3, dash='dash'),\n",
    "                                                              dict(y=self.summary['Entry Upper Bound'], color='red', width=3, dash='dash'),\n",
    "                                                              dict(y=self.summary['Entry Lower Bound'], color='red', width=3, dash='dash'),\n",
    "                                                              dict(y=self.summary['Stop Upper Bound'], color='black', width=3, dash='dash'),\n",
    "                                                              dict(y=self.summary['Stop Lower Bound'], color='black', width=3, dash='dash')])\n",
    "        \n",
    "        \n",
    "        # 3. Cumulative Returns\n",
    "        np.exp(backtest_book['P&L'].cumsum()).iplot(title='Cumulative Returns', xTitle='Time', \n",
    "                                                    yTitle='Cumulative Returns', width=2,\n",
    "                                                    hline=[dict(y=1, color='blue', width=3, dash='dash')])\n",
    "\n",
    "        # 4. Rolling Volatility\n",
    "        backtest_book[['Volatility 6M']].iplot(title='Rolling Volatility 6M', \n",
    "                                               xTitle='Time', yTitle='Rolling Volatility', \n",
    "                                               width=2, legend='top',\n",
    "                                               hline=[dict(y=backtest_book['Volatility 6M'].mean(), color='orange', width=3, dash='dash')])\n",
    "\n",
    "        # 5. Rolling Beta\n",
    "        backtest_book[['Beta 6M']].iplot(title='Rolling Beta 6M', xTitle='Time',\n",
    "                                         yTitle='Rolling Beta', width=1, legend='top',\n",
    "                                         hline=[dict(y=backtest_book['beta 6M'].mean(), color='orange', width=3, dash='dash')])\n",
    "\n",
    "        # 6. Rolling Alpha \n",
    "        backtest_book[['Alpha 6M']].iplot(title='Rolling Alpha 6M', xTitle='Time',\n",
    "                                          yTitle='Rolling Alpha', width=1, legend='top',\n",
    "                                          hline=[dict(y=backtest_book['Alpha 6M'].mean(), color='orange', width=3, dash='dash')])\n",
    "\n",
    "        # 7. Rolling Information Ratio\n",
    "        backtest_book[['Information Ratio (IR) 6M']].iplot(title='Rolling Information Ratio(IR) 6M',\n",
    "                                                           xTitle='Time', yTitle='Rolling Information Ratio(IR)', \n",
    "                                                           width=1, legend='top',\n",
    "                                                           hline=[dict(y=backtest_book['Information Ratio(IR) 6M'].mean(), color='orange', width=3, dash='dash')])\n",
    "\n",
    "        # 8. Rolling Sharpe Ratio\n",
    "        backtest_book[['SR 6M']].iplot(title='Rolling Sharpe Ratio 6M', xTitle='Time',\n",
    "                                       yTitle='Rolling Sharpe Ratio', width=1, legend='top', \n",
    "                                       hline=[dict(y=backtest_book['SR 6M'].mean(), color='orange', width=3, dash='dash')])\n",
    "\n",
    "        # 9. Underwater Plot\n",
    "        (- backtest_book['Drawdown']*100).iplot(title='Underwater Plot', xTitle='Time', yTitle='Drawdown', width=2, fill=True)\n",
    "\n",
    "        # 10. Daily VaR 99%\n",
    "        (backtest_book['Daily VaR (99%)']*100).iplot(title='Daily VaR at 99%', xTitle='Time', yTitle='VaR', width=2, fill=True,\n",
    "                                                   hline=[dict(y=backtest_book['Daily VaR (99%)'].mean()*100, color='blue', width=3, dash='dash')])\n",
    "        \n",
    "        \n",
    "    def get_return(self):\n",
    "        \n",
    "        return np.exp(self.summary['Cummulative Return'])*100\n",
    "        \n",
    "    def get_Sharpe_ratio(self): \n",
    "        \n",
    "        return self.SR\n",
    "    \n",
    "    def get_num_of_trades(self):\n",
    "       \n",
    "        return self.summary['Total Number of Trades']\n",
    "    \n",
    "    def get_return_per_trade(self):\n",
    "        \n",
    "        for i in range(int(self.summary['Total Number of Trades'])):\n",
    "            print('Trade ',i+1, 'has ', round(np.exp(self.summary['Return per trade'][i])*100, 2),'%', ' return.')\n",
    "        return\n",
    "    \n",
    "    def get_vol(self):\n",
    "        \n",
    "        return round(self.summary['Trading Book']['P&L'].std()*np.sqrt(252)*100, 2)\n",
    "    \n",
    "    def update_mu_e(self, bias):\n",
    "        \"\"\"\n",
    "        This function is to update the mu_e to the slightly biased new mu_e\n",
    "        Input:\n",
    "            bias: the percentage of bias on the parameter mu_e\n",
    "        mu_e is updated to mu_e*(1+bias)\n",
    "        \"\"\"\n",
    "        self.mu_e = self.mu_e*(1+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1 = commodity_train[['Lean Hogs', 'Crude Oil WTI']]\n",
    "pair2 = commodity_train[['Silver', 'Sugar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading instance\n",
    "trade_1 = pairs_trading()\n",
    "trade_2 = pairs_trading()\n",
    "# Get the parameters of the cointegration pair (mu_e, sigma_eq, beta_coint)\n",
    "trade_1.fitting(pair1['Crude Oil WTI'], pair1['Lean Hogs'])\n",
    "trade_2.fitting(pair2['Sugar'], pair2['Silver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading Book':                            Lean Hogs  Crude Oil WTI  ask_price_Lean Hogs  \\\n",
       " Date                                                                       \n",
       " 2004-08-03 00:00:00-04:00  77.375000      44.150002            77.375000   \n",
       " 2004-08-04 00:00:00-04:00  78.550003      42.830002            78.550003   \n",
       " 2004-08-05 00:00:00-04:00  78.625000      44.410000            78.625000   \n",
       " 2004-08-06 00:00:00-04:00  79.250000      43.950001            79.250000   \n",
       " 2004-08-09 00:00:00-04:00  79.199997      44.840000            79.199997   \n",
       " ...                              ...            ...                  ...   \n",
       " 2018-09-10 00:00:00-04:00  55.950001      67.540001            55.950001   \n",
       " 2018-09-11 00:00:00-04:00  54.474998      69.250000            54.474998   \n",
       " 2018-09-12 00:00:00-04:00  55.799999      70.370003            55.799999   \n",
       " 2018-09-13 00:00:00-04:00  55.674999      68.589996            55.674999   \n",
       " 2018-09-14 00:00:00-04:00  56.224998      68.989998            56.224998   \n",
       " \n",
       "                            bid_price_Lean Hogs  ask_price_Crude Oil WTI  \\\n",
       " Date                                                                      \n",
       " 2004-08-03 00:00:00-04:00            77.375000                44.150002   \n",
       " 2004-08-04 00:00:00-04:00            78.550003                42.830002   \n",
       " 2004-08-05 00:00:00-04:00            78.625000                44.410000   \n",
       " 2004-08-06 00:00:00-04:00            79.250000                43.950001   \n",
       " 2004-08-09 00:00:00-04:00            79.199997                44.840000   \n",
       " ...                                        ...                      ...   \n",
       " 2018-09-10 00:00:00-04:00            55.950001                67.540001   \n",
       " 2018-09-11 00:00:00-04:00            54.474998                69.250000   \n",
       " 2018-09-12 00:00:00-04:00            55.799999                70.370003   \n",
       " 2018-09-13 00:00:00-04:00            55.674999                68.589996   \n",
       " 2018-09-14 00:00:00-04:00            56.224998                68.989998   \n",
       " \n",
       "                            bid_price_Crude Oil WTI   Residual  Status  Signal  \\\n",
       " Date                                                                            \n",
       " 2004-08-03 00:00:00-04:00                44.150002  11.700524       0     0.0   \n",
       " 2004-08-04 00:00:00-04:00                42.830002  13.444343       0     0.0   \n",
       " 2004-08-05 00:00:00-04:00                44.410000  12.838485       0     0.0   \n",
       " 2004-08-06 00:00:00-04:00                43.950001  13.661708       0     0.0   \n",
       " 2004-08-09 00:00:00-04:00                44.840000  13.228185       0     0.0   \n",
       " ...                                            ...        ...     ...     ...   \n",
       " 2018-09-10 00:00:00-04:00                67.540001 -19.803734       0     0.0   \n",
       " 2018-09-11 00:00:00-04:00                69.250000 -22.015612       0     0.0   \n",
       " 2018-09-12 00:00:00-04:00                70.370003 -21.173245       0     0.0   \n",
       " 2018-09-13 00:00:00-04:00                68.589996 -20.531201       0     0.0   \n",
       " 2018-09-14 00:00:00-04:00                68.989998 -20.153572       0     0.0   \n",
       " \n",
       "                            Entry  Exit  ask_price_port  bid_price_port  \\\n",
       " Date                                                                     \n",
       " 2004-08-03 00:00:00-04:00    0.0     0       58.349806       58.349806   \n",
       " 2004-08-04 00:00:00-04:00    0.0     0       60.093625       60.093625   \n",
       " 2004-08-05 00:00:00-04:00    0.0     0       59.487767       59.487767   \n",
       " 2004-08-06 00:00:00-04:00    0.0     0       60.310990       60.310990   \n",
       " 2004-08-09 00:00:00-04:00    0.0     0       59.877467       59.877467   \n",
       " ...                          ...   ...             ...             ...   \n",
       " 2018-09-10 00:00:00-04:00    0.0     0       26.845548       26.845548   \n",
       " 2018-09-11 00:00:00-04:00    0.0     0       24.633670       24.633670   \n",
       " 2018-09-12 00:00:00-04:00    0.0     0       25.476037       25.476037   \n",
       " 2018-09-13 00:00:00-04:00    0.0     0       26.118080       26.118080   \n",
       " 2018-09-14 00:00:00-04:00    0.0     0       26.495710       26.495710   \n",
       " \n",
       "                            price_port  log_ret_port  P&L  \n",
       " Date                                                      \n",
       " 2004-08-03 00:00:00-04:00   58.349806     -0.021485 -0.0  \n",
       " 2004-08-04 00:00:00-04:00   60.093625      0.029448  0.0  \n",
       " 2004-08-05 00:00:00-04:00   59.487767     -0.010133 -0.0  \n",
       " 2004-08-06 00:00:00-04:00   60.310990      0.013744  0.0  \n",
       " 2004-08-09 00:00:00-04:00   59.877467     -0.007214 -0.0  \n",
       " ...                               ...           ...  ...  \n",
       " 2018-09-10 00:00:00-04:00   26.845548      0.014653  0.0  \n",
       " 2018-09-11 00:00:00-04:00   24.633670     -0.085986 -0.0  \n",
       " 2018-09-12 00:00:00-04:00   25.476037      0.033624  0.0  \n",
       " 2018-09-13 00:00:00-04:00   26.118080      0.024890  0.0  \n",
       " 2018-09-14 00:00:00-04:00   26.495710      0.014355  0.0  \n",
       " \n",
       " [2699 rows x 16 columns],\n",
       " 'Cummulative Returns': 0.6031039549114068,\n",
       " 'Annualised Return': 0.05631055822070193,\n",
       " 'Total Number of Trades': 1.0,\n",
       " 'Return Per Trade': [0.6031039549114068],\n",
       " 'Average Return Per Trade': 0.6031039549114068,\n",
       " 'Days Per Trade': [217],\n",
       " 'Entry Dates': [Timestamp('2014-06-30 00:00:00-0400', tz='America/New_York')],\n",
       " 'Exit Dates': [Timestamp('2015-02-02 00:00:00-0500', tz='America/New_York')],\n",
       " 'Entry Prices for Crude Oil WTI': [105.37000274658203],\n",
       " 'Entry Prices for Lean Hogs': [132.64999389648438],\n",
       " 'Exit Prices for Crude Oil WTI': [49.56999969482422],\n",
       " 'Exit Prices for Lean Hogs': [66.32499694824219],\n",
       " 'Entry Upper Bound': 38.831260981736236,\n",
       " 'Entry Lower Bound': -41.039221215138696,\n",
       " 'Exit Upper Bound': -1.1039801167012289,\n",
       " 'Exit Lower Bound': -1.1039801167012289,\n",
       " 'Stop Upper Bound': 118.70174317861117,\n",
       " 'Stop Lower Bound': -120.90970341201361}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the value of parameters for trading\n",
    "Z = 1 \n",
    "Z_e = 0\n",
    "Z_s = 3\n",
    "spread = 0\n",
    "long_cost = 0\n",
    "short_cost = 0\n",
    "# Trading on the training set\n",
    "trade_1.trading(pair1, 'Crude Oil WTI', 'Lean Hogs', Z, Z_e, Z_s, spread, long_cost, short_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading Book':                            Silver  Sugar  ask_price_Silver  bid_price_Silver  \\\n",
       " Date                                                                           \n",
       " 2004-08-03 00:00:00-04:00   6.675   8.38             6.675             6.675   \n",
       " 2004-08-04 00:00:00-04:00   6.727   8.15             6.727             6.727   \n",
       " 2004-08-05 00:00:00-04:00   6.740   8.13             6.740             6.740   \n",
       " 2004-08-06 00:00:00-04:00   6.767   8.17             6.767             6.767   \n",
       " 2004-08-09 00:00:00-04:00   6.729   8.08             6.729             6.729   \n",
       " ...                           ...    ...               ...               ...   \n",
       " 2018-09-10 00:00:00-04:00  14.079  11.20            14.079            14.079   \n",
       " 2018-09-11 00:00:00-04:00  14.052  11.18            14.052            14.052   \n",
       " 2018-09-12 00:00:00-04:00  14.192  11.67            14.192            14.192   \n",
       " 2018-09-13 00:00:00-04:00  14.143  11.68            14.143            14.143   \n",
       " 2018-09-14 00:00:00-04:00  14.042  11.16            14.042            14.042   \n",
       " \n",
       "                            ask_price_Sugar  bid_price_Sugar   Residual  \\\n",
       " Date                                                                     \n",
       " 2004-08-03 00:00:00-04:00             8.38             8.38 -43.585406   \n",
       " 2004-08-04 00:00:00-04:00             8.15             8.15 -43.434293   \n",
       " 2004-08-05 00:00:00-04:00             8.13             8.13 -43.412676   \n",
       " 2004-08-06 00:00:00-04:00             8.17             8.17 -43.402912   \n",
       " 2004-08-09 00:00:00-04:00             8.08             8.08 -43.402129   \n",
       " ...                                    ...              ...        ...   \n",
       " 2018-09-10 00:00:00-04:00            11.20            11.20 -37.396605   \n",
       " 2018-09-11 00:00:00-04:00            11.18            11.18 -37.414987   \n",
       " 2018-09-12 00:00:00-04:00            11.67            11.67 -37.486138   \n",
       " 2018-09-13 00:00:00-04:00            11.68            11.68 -37.539448   \n",
       " 2018-09-14 00:00:00-04:00            11.16            11.16 -37.416368   \n",
       " \n",
       "                            Status  Signal  Entry  Exit  ask_price_port  \\\n",
       " Date                                                                     \n",
       " 2004-08-03 00:00:00-04:00       0     0.0    0.0     0        3.063876   \n",
       " 2004-08-04 00:00:00-04:00       0     0.0    0.0     0        3.214988   \n",
       " 2004-08-05 00:00:00-04:00       0     0.0    0.0     0        3.236606   \n",
       " 2004-08-06 00:00:00-04:00       0     0.0    0.0     0        3.246370   \n",
       " 2004-08-09 00:00:00-04:00       0     0.0    0.0     0        3.247153   \n",
       " ...                           ...     ...    ...   ...             ...   \n",
       " 2018-09-10 00:00:00-04:00       0     0.0    0.0     0        9.252677   \n",
       " 2018-09-11 00:00:00-04:00       0     0.0    0.0     0        9.234295   \n",
       " 2018-09-12 00:00:00-04:00       0     0.0    0.0     0        9.163144   \n",
       " 2018-09-13 00:00:00-04:00       0     0.0    0.0     0        9.109834   \n",
       " 2018-09-14 00:00:00-04:00       0     0.0    0.0     0        9.232914   \n",
       " \n",
       "                            bid_price_port  price_port  log_ret_port  P&L  \n",
       " Date                                                                      \n",
       " 2004-08-03 00:00:00-04:00        3.063876    3.063876      0.022881  0.0  \n",
       " 2004-08-04 00:00:00-04:00        3.214988    3.214988      0.048143  0.0  \n",
       " 2004-08-05 00:00:00-04:00        3.236606    3.236606      0.006702  0.0  \n",
       " 2004-08-06 00:00:00-04:00        3.246370    3.246370      0.003012  0.0  \n",
       " 2004-08-09 00:00:00-04:00        3.247153    3.247153      0.000241  0.0  \n",
       " ...                                   ...         ...           ...  ...  \n",
       " 2018-09-10 00:00:00-04:00        9.252677    9.252677     -0.007523 -0.0  \n",
       " 2018-09-11 00:00:00-04:00        9.234295    9.234295     -0.001989 -0.0  \n",
       " 2018-09-12 00:00:00-04:00        9.163144    9.163144     -0.007735 -0.0  \n",
       " 2018-09-13 00:00:00-04:00        9.109834    9.109834     -0.005835 -0.0  \n",
       " 2018-09-14 00:00:00-04:00        9.232914    9.232914      0.013420  0.0  \n",
       " \n",
       " [2699 rows x 16 columns],\n",
       " 'Cummulative Returns': 0.0,\n",
       " 'Annualised Return': 0.0,\n",
       " 'Total Number of Trades': 0.0,\n",
       " 'Return Per Trade': [],\n",
       " 'Average Return Per Trade': 'No Trade',\n",
       " 'Days Per Trade': [],\n",
       " 'Entry Dates': [],\n",
       " 'Exit Dates': [],\n",
       " 'Entry Prices for Sugar': [],\n",
       " 'Entry Prices for Silver': [],\n",
       " 'Exit Prices for Sugar': [],\n",
       " 'Exit Prices for Silver': [],\n",
       " 'Entry Upper Bound': 38.831260981736236,\n",
       " 'Entry Lower Bound': -41.039221215138696,\n",
       " 'Exit Upper Bound': -1.1039801167012289,\n",
       " 'Exit Lower Bound': -1.1039801167012289,\n",
       " 'Stop Upper Bound': 118.70174317861117,\n",
       " 'Stop Lower Bound': -120.90970341201361}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_1.trading(pair2, 'Sugar', 'Silver', Z, Z_e, Z_s, spread, long_cost, short_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m MADD \u001b[39m=\u001b[39m \u001b[39m0.7\u001b[39m\n\u001b[0;32m      3\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m trade_1\u001b[39m.\u001b[39;49mbacktest(MADD, output)\n",
      "Cell \u001b[1;32mIn[13], line 472\u001b[0m, in \u001b[0;36mpairs_trading.backtest\u001b[1;34m(self, MADD, output)\u001b[0m\n\u001b[0;32m    469\u001b[0m             drawdowns\u001b[39m.\u001b[39mappend(drawdown)\n\u001b[0;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m drawdowns\n\u001b[1;32m--> 472\u001b[0m backtest_book[\u001b[39m'\u001b[39m\u001b[39mDrawdown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m get_drawdown(backtest_book[\u001b[39m'\u001b[39;49m\u001b[39mP&L\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mcumsum())\n\u001b[0;32m    474\u001b[0m \u001b[39m####################### VaR at 99% ########################\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_VaR\u001b[39m(array):\n",
      "Cell \u001b[1;32mIn[13], line 461\u001b[0m, in \u001b[0;36mpairs_trading.backtest.<locals>.get_drawdown\u001b[1;34m(array)\u001b[0m\n\u001b[0;32m    459\u001b[0m array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(array)\u001b[39m*\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    460\u001b[0m drawdowns \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 461\u001b[0m max_so_far \u001b[39m=\u001b[39m array[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m    462\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(array)):\n\u001b[0;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m array[i] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_so_far:\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\pythonlab\\lib\\site-packages\\pandas\\core\\series.py:978\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    975\u001b[0m     key \u001b[39m=\u001b[39m unpack_1tuple(key)\n\u001b[0;32m    977\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m--> 978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# set the value of parameters for backtesting\n",
    "MADD = 0.7\n",
    "output = True\n",
    "trade_1.backtest(MADD, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
